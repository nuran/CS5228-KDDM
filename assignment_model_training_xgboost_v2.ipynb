{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "from future.backports.datetime import datetime\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-28T14:08:36.155408Z",
     "start_time": "2024-10-28T14:08:36.009563Z"
    }
   },
   "id": "33768d0076b0f95d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-28T14:08:38.845903Z",
     "start_time": "2024-10-28T14:08:38.068637Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "class DataPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.model_to_make_mapping = None\n",
    "        self.overall_medians = {}\n",
    "\n",
    "    def fit(self, train_df):\n",
    "        \"\"\"\n",
    "        Fit the preprocessing on the training data to create mappings and overall statistics.\n",
    "        \"\"\"\n",
    "        # Create model_to_make mapping using non-null entries in the training dataset\n",
    "        self.model_to_make_mapping = train_df.dropna(subset=['make']).set_index('model')['make'].str.lower().to_dict()\n",
    "\n",
    "        # Calculate overall medians for columns where necessary\n",
    "        self.overall_medians = {\n",
    "            'manufactured': train_df['manufactured'].median(),\n",
    "            'power': train_df['power'].median(),\n",
    "            'mileage': train_df['mileage'].median(),\n",
    "            'engine_cap': train_df['engine_cap'].median(),\n",
    "            'depreciation': train_df['depreciation'].median(),\n",
    "            'road_tax': train_df['road_tax'].mean(),\n",
    "            'dereg_value': train_df['dereg_value'].mean(),\n",
    "            'coe': train_df['coe'].mean(),\n",
    "            'omv': train_df['omv'].mean(),\n",
    "            'arf': train_df['arf'].mean(),\n",
    "        }\n",
    "\n",
    "    def fill_missing_make(self, df):\n",
    "        \"\"\"\n",
    "        Fill missing values in the 'make' column using the 'model' column based on the mapping dictionary.\n",
    "        \"\"\"\n",
    "        df['make'] = df['make'].fillna(df['model'].str.lower().map(self.model_to_make_mapping))\n",
    "\n",
    "    def fill_missing_with_group_mode_or_median(self, df, column_name):\n",
    "        \"\"\"\n",
    "        Fill missing values in a specified column using the mode of each group (model).\n",
    "        If the mode is not available, use the median of the training dataset.\n",
    "        \"\"\"\n",
    "        overall_median = self.overall_medians[column_name]\n",
    "        df[column_name] = df.groupby('model')[column_name].transform(\n",
    "            lambda x: x.fillna(x.mode().iloc[0] if not x.mode().empty else overall_median)\n",
    "        )\n",
    "\n",
    "    def fill_missing_with_group_mean_or_median(self, df, column_name):\n",
    "        \"\"\"\n",
    "        Fill missing values in a specified column using the mean of each group (model).\n",
    "        If the group mean is not available, use the overall mean from the training dataset.\n",
    "        \"\"\"\n",
    "        overall_mean = self.overall_medians[column_name]\n",
    "        df[column_name] = df.groupby('model')[column_name].transform(\n",
    "            lambda x: x.fillna(x.mean() if not x.empty else overall_mean)\n",
    "        )\n",
    "        \n",
    "    def transform(self, df):\n",
    "        \"\"\"\n",
    "        Apply the preprocessing steps to a dataset (training or test) using the fitted parameters.\n",
    "        \"\"\"\n",
    "        # Fill missing 'make' values using model information\n",
    "        self.fill_missing_make(df)\n",
    "\n",
    "        # Fill missing values for other columns using appropriate methods\n",
    "        self.fill_missing_with_group_mode_or_median(df, 'manufactured')\n",
    "        self.fill_missing_with_group_mode_or_median(df, 'power')\n",
    "        self.fill_missing_with_group_mode_or_median(df, 'mileage')\n",
    "        self.fill_missing_with_group_mode_or_median(df, 'engine_cap')\n",
    "        self.fill_missing_with_group_mode_or_median(df, 'depreciation')\n",
    "        self.fill_missing_with_group_mode_or_median(df, 'road_tax')\n",
    "        self.fill_missing_with_group_mean_or_median(df, 'dereg_value')\n",
    "        self.fill_missing_with_group_mean_or_median(df, 'coe')\n",
    "        self.fill_missing_with_group_mean_or_median(df, 'omv')\n",
    "        self.fill_missing_with_group_mean_or_median(df, 'arf')\n",
    "\n",
    "        # Calculate derived features\n",
    "        # current_year = datetime.now().year\n",
    "        # df['vehicle_age'] = current_year - df['manufactured']\n",
    "        # df['coe_days'] = (datetime.now() - pd.to_datetime(df['coe'], errors='coerce')).dt.days\n",
    "\n",
    "        return df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-28T14:20:50.092760Z",
     "start_time": "2024-10-28T14:20:50.009871Z"
    }
   },
   "id": "907431efd08dbee",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T14:28:21.514923Z",
     "start_time": "2024-10-28T14:28:21.436698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "class OutlierRemover:\n",
    "    def __init__(self, factor=1.5):\n",
    "        self.factor = factor\n",
    "\n",
    "    def remove_outliers(self, X, numerical_features):\n",
    "        X_filtered = X.copy()\n",
    "        \n",
    "        for feature in numerical_features:\n",
    "            Q1 = X_filtered[feature].quantile(0.25)\n",
    "            Q3 = X_filtered[feature].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            is_not_outlier = ~((X_filtered[feature] < (Q1 - self.factor * IQR)) | \n",
    "                               (X_filtered[feature] > (Q3 + self.factor * IQR)))\n",
    "            X_filtered = X_filtered[is_not_outlier]\n",
    "        \n",
    "        X[numerical_features] = X_filtered[numerical_features]\n",
    "        return X\n",
    "\n"
   ],
   "id": "290d94492bd182ba",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T14:29:07.721585Z",
     "start_time": "2024-10-28T14:29:04.738094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "features = ['make', 'model','type_of_vehicle', 'manufactured', 'mileage', 'power','engine_cap', 'depreciation','road_tax','dereg_value','coe', 'omv', 'arf' ]\n",
    "target = 'price'\n",
    "numerical_features = ['manufactured', 'mileage', 'power','engine_cap', 'depreciation','road_tax','dereg_value','coe', 'omv', 'arf']\n",
    "categorical_features = ['make', 'model','type_of_vehicle']\n",
    "outlier_remover = OutlierRemover(factor=1.5)\n",
    "\n",
    "preprocessor = DataPreprocessor()\n",
    "\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "\n",
    "train_df = train_df.dropna(subset=[target])\n",
    "\n",
    "preprocessor.fit(train_df)\n",
    "\n",
    "train_df = preprocessor.transform(train_df)\n",
    "# train_df = outlier_remover.remove_outliers(train_df, numerical_features)\n",
    "test_df = preprocessor.transform(test_df)\n",
    "\n",
    "X = train_df[features]\n",
    "y = train_df[:train_df.shape[0]]\n",
    "y = y[target]\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "id": "4e965ec1ce855863",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T14:29:10.821421Z",
     "start_time": "2024-10-28T14:29:10.742954Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class IQRBasedOutlierRemover(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, factor=1.5):\n",
    "        self.factor = factor\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = pd.DataFrame(X)  # Convert to DataFrame for easier manipulation\n",
    "        Q1 = X.quantile(0.25)\n",
    "        Q3 = X.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        # Only keep rows where all features are within the IQR bounds\n",
    "        is_not_outlier = ~((X < (Q1 - self.factor * IQR)) | (X > (Q3 + self.factor * IQR))).any(axis=1)\n",
    "        return X[is_not_outlier].values  # Return as a numpy array for compatibility with sklearn\n"
   ],
   "id": "5f1f1bd9a618f881",
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Step 3: Create preprocessing pipelines for both numeric and categorical features\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    # ('outlier_remover', IQRBasedOutlierRemover()),  # Step to remove outliers\n",
    "    ('imputer', SimpleImputer(strategy='mean')),    # Imputation step\n",
    "    ('robust_scaler', RobustScaler()),              # RobustScaler step\n",
    "    ('standard_scaler', StandardScaler())           # StandardScaler step\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Step 4: Combine preprocessing steps into a column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Step 5: Create a pipeline that first preprocesses the data and then applies the XGBoost model\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    # ('model', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "    ('model', XGBRegressor(n_estimators=500, learning_rate=0.1, max_depth=20, random_state=42))\n",
    "])\n",
    "\n",
    "# Step 6: Split the data into training and testing sets\n",
    "\n",
    "\n",
    "# Step 7: Fit the model pipeline to the training data\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Step 8: Make predictions on the test set\n",
    "y_pred = model_pipeline.predict(X_valid)\n",
    "\n",
    "# Step 9: Evaluate the model's performance\n",
    "mae = mean_absolute_error(y_valid, y_pred)\n",
    "mse = mean_squared_error(y_valid, y_pred)\n",
    "rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
    "r2 = r2_score(y_valid, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f'Mean Absolute Error (MAE): {mae:.2f}')\n",
    "print(f'Mean Squared Error (MSE): {mse:.2f}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse:.2f}')\n",
    "print(f'R-squared (R2): {r2:.2f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-28T14:31:22.391666Z",
     "start_time": "2024-10-28T14:31:07.719447Z"
    }
   },
   "id": "c562da927fb83a5c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 5805.47\n",
      "Mean Squared Error (MSE): 752253042.34\n",
      "Root Mean Squared Error (RMSE): 27427.23\n",
      "R-squared (R2): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\bin\\envs\\sem4_assignments\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T17:04:29.533332Z",
     "start_time": "2024-10-08T17:04:29.419160Z"
    }
   },
   "cell_type": "code",
   "source": "X_train.head()",
   "id": "b7da6d208d7e4a45",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         make   model  manufactured   mileage  power  engine_cap  \\\n",
       "23311   isuzu   npr85        2019.0   14329.0  111.0      2999.0   \n",
       "23623   honda     fit        2009.0   55000.0   73.0      1339.0   \n",
       "1020   toyota  sienta        2018.0   80346.0   79.0      1496.0   \n",
       "12645   volvo     v40        2018.0   68000.0  140.0      1969.0   \n",
       "1533      kia  carens        2015.0  130000.0  122.0      1999.0   \n",
       "\n",
       "       depreciation     road_tax  dereg_value    coe      omv      arf  \\\n",
       "23311       14860.0  1462.160899      13348.0  22085  37994.0   1900.0   \n",
       "23623       13510.0   885.000000        123.0  14920  14211.0  14211.0   \n",
       "1020        14530.0   682.000000      25880.0  38001  17199.0  17199.0   \n",
       "12645       15770.0  1176.000000      35358.0  36901  22799.0  23919.0   \n",
       "1533        15540.0  1212.000000      20117.0  58190  21074.0  21504.0   \n",
       "\n",
       "         price  \n",
       "23311  89800.0  \n",
       "23623    700.0  \n",
       "1020   64800.0  \n",
       "12645  92800.0  \n",
       "1533   32888.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>make</th>\n",
       "      <th>model</th>\n",
       "      <th>manufactured</th>\n",
       "      <th>mileage</th>\n",
       "      <th>power</th>\n",
       "      <th>engine_cap</th>\n",
       "      <th>depreciation</th>\n",
       "      <th>road_tax</th>\n",
       "      <th>dereg_value</th>\n",
       "      <th>coe</th>\n",
       "      <th>omv</th>\n",
       "      <th>arf</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23311</th>\n",
       "      <td>isuzu</td>\n",
       "      <td>npr85</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>14329.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>2999.0</td>\n",
       "      <td>14860.0</td>\n",
       "      <td>1462.160899</td>\n",
       "      <td>13348.0</td>\n",
       "      <td>22085</td>\n",
       "      <td>37994.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>89800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23623</th>\n",
       "      <td>honda</td>\n",
       "      <td>fit</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1339.0</td>\n",
       "      <td>13510.0</td>\n",
       "      <td>885.000000</td>\n",
       "      <td>123.0</td>\n",
       "      <td>14920</td>\n",
       "      <td>14211.0</td>\n",
       "      <td>14211.0</td>\n",
       "      <td>700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>toyota</td>\n",
       "      <td>sienta</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>80346.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1496.0</td>\n",
       "      <td>14530.0</td>\n",
       "      <td>682.000000</td>\n",
       "      <td>25880.0</td>\n",
       "      <td>38001</td>\n",
       "      <td>17199.0</td>\n",
       "      <td>17199.0</td>\n",
       "      <td>64800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12645</th>\n",
       "      <td>volvo</td>\n",
       "      <td>v40</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>68000.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>15770.0</td>\n",
       "      <td>1176.000000</td>\n",
       "      <td>35358.0</td>\n",
       "      <td>36901</td>\n",
       "      <td>22799.0</td>\n",
       "      <td>23919.0</td>\n",
       "      <td>92800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533</th>\n",
       "      <td>kia</td>\n",
       "      <td>carens</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>15540.0</td>\n",
       "      <td>1212.000000</td>\n",
       "      <td>20117.0</td>\n",
       "      <td>58190</td>\n",
       "      <td>21074.0</td>\n",
       "      <td>21504.0</td>\n",
       "      <td>32888.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Prepare a function to log model parameters and evaluation metrics. It should be in a single line saved to a csv for easy tracking.\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def log_model(model_name, model_params, evaluation_metrics):\n",
    "    \"\"\"\n",
    "    Log the model parameters and evaluation metrics to a CSV file.\n",
    "    \"\"\"\n",
    "    # Create a new CSV file if it does not exist\n",
    "    if not os.path.exists('model_logs.csv'):\n",
    "        with open('model_logs.csv', 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['Model', 'Parameters', 'MAE', 'MSE', 'RMSE', 'R2'])\n",
    "\n",
    "    # Append the results to the CSV file\n",
    "    with open('model_logs.csv', 'a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([model_name, model_params, *evaluation_metrics])"
   ],
   "id": "593818b18266a2b8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T14:46:14.833644Z",
     "start_time": "2024-10-28T14:31:53.415059Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Assume you have X_train and X_valid as your training and validation datasets\n",
    "# Identify categorical and numerical features\n",
    "categorical_features = X_train.select_dtypes(include=['object']).columns\n",
    "numerical_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Preprocessing pipeline for categorical features (OneHotEncoder in this example)\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Preprocessing pipeline for numerical features\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('robust_scaler', RobustScaler()),     \n",
    "    ('standard_scaler', StandardScaler())  \n",
    "])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the complete pipeline including preprocessing and the XGBRegressor model\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', XGBRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'model__n_estimators': [100, 200, 500, 750, 1000],\n",
    "    'model__learning_rate': [0.01, 0.05, 0.075, 0.1, 0.2],\n",
    "    'model__max_depth': [3, 5, 10, 20, 30, 40, 50],\n",
    "    'model__subsample': [0.5, 0.6, 0.8, 1.0],\n",
    "    'model__colsample_bytree': [0.4, 0.6, 0.8, 1.0],\n",
    "    'model__min_child_weight': [1, 5, 10, 20]\n",
    "}\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "# GridSearchCV is another option to perform exhaustive search over specified parameter values\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=50,  # Number of different combinations to try\n",
    "    scoring='neg_mean_absolute_error',  # Use MAE as the scoring metric\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit the RandomizedSearchCV on the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model and parameters\n",
    "best_model = random_search.best_estimator_\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "# Save the best model to a file\n",
    "joblib.dump(best_model, 'best_xgb_model.pkl')\n",
    "\n",
    "# Evaluate the model with the best parameters on validation data\n",
    "y_pred = best_model.predict(X_valid)\n",
    "mae = mean_absolute_error(y_valid, y_pred)\n",
    "mse = mean_squared_error(y_valid, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f'Best Parameters: {best_params}')\n",
    "print(f'MAE: {mae}')\n",
    "print(f'MSE: {mse}')\n",
    "print(f'RMSE: {rmse}')\n",
    "\n",
    "\n"
   ],
   "id": "f17850a89c295da4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best Parameters: {'model__subsample': 0.8, 'model__n_estimators': 1000, 'model__min_child_weight': 5, 'model__max_depth': 40, 'model__learning_rate': 0.01, 'model__colsample_bytree': 1.0}\n",
      "MAE: 5226.518661328125\n",
      "MSE: 689199269.2266082\n",
      "RMSE: 26252.604998868363\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "source": [
    "test_predictions = model_pipeline.predict(test_df)\n",
    "output = pd.DataFrame({'Id': test_df.index, 'Predicted': test_predictions})\n",
    "output.to_csv('predictions_v1.2.csv', index=False)\n",
    "\n",
    "print(output.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-28T14:48:27.428976Z",
     "start_time": "2024-10-28T14:48:27.148567Z"
    }
   },
   "id": "77a6d42c08eac7af",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id      Predicted\n",
      "0   0   20137.445312\n",
      "1   1   35312.312500\n",
      "2   2  146297.531250\n",
      "3   3   79213.367188\n",
      "4   4   26394.638672\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "source": "test_df.head()",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-08T17:12:08.648631Z",
     "start_time": "2024-10-08T17:12:08.543791Z"
    }
   },
   "id": "cc20bcd85d2b911",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   listing_id                               title    make   model  \\\n",
       "0     1303772                  Honda Vezel 1.5A X   honda   vezel   \n",
       "1     1323166  Mazda 3 1.6A SP (COE till 10/2027)   mazda       3   \n",
       "2     1308405       MINI Cooper S Countryman 2.0A    mini  cooper   \n",
       "3     1216706                  Toyota Vios 1.5A G  toyota    vios   \n",
       "4     1298206                     Mazda 3 HB 1.5A   mazda       3   \n",
       "\n",
       "                                         description  manufactured  \\\n",
       "0                                               4614        2015.0   \n",
       "1  extremely well maintained and in pristine cond...        2007.0   \n",
       "2  1 owner! beautiful island blue color! eurokars...        2019.0   \n",
       "3  fully agent maintain! genuine low mileage at 5...        2019.0   \n",
       "4  workshop check/sta evaluation available. accid...        2015.0   \n",
       "\n",
       "  original_reg_date     reg_date  type_of_vehicle  \\\n",
       "0               NaN  29-apr-2015              suv   \n",
       "1               NaN  26-oct-2007  mid-sized sedan   \n",
       "2               NaN  27-mar-2020       sports car   \n",
       "3               NaN  28-jun-2019  mid-sized sedan   \n",
       "4               NaN  19-nov-2015        hatchback   \n",
       "\n",
       "                                   category  ... dereg_value   mileage  \\\n",
       "0                                  parf car  ...      9582.0  112000.0   \n",
       "1  coe car, premium ad car, low mileage car  ...     13644.0  120000.0   \n",
       "2                                  parf car  ...     54818.0   43000.0   \n",
       "3                  parf car, premium ad car  ...     26363.0   53300.0   \n",
       "4                  parf car, premium ad car  ...     15197.0  149000.0   \n",
       "\n",
       "       omv      arf  opc_scheme  lifespan   eco_category  \\\n",
       "0  19229.0   9229.0         NaN       NaN  uncategorized   \n",
       "1  14347.0  15782.0         NaN       NaN  uncategorized   \n",
       "2  39863.0  47809.0         NaN       NaN  uncategorized   \n",
       "3  15573.0  15573.0         NaN       NaN  uncategorized   \n",
       "4  18097.0  13097.0         NaN       NaN  uncategorized   \n",
       "\n",
       "                                            features  \\\n",
       "0  powerful 1.5l i-vtec engine producing 128bhp, ...   \n",
       "1  fuel efficient 1.6l 4-cylinder inline 16-valve...   \n",
       "2  output of 141kw, 189bhp at 5000rpm to 6000rpm,...   \n",
       "3  1.5l 4 cylinder 16 valves dohc vvt-i engine, 7...   \n",
       "4  1.5l 4 cylinder inline dohc 16 valves skyactiv...   \n",
       "\n",
       "                                         accessories  indicative_price  \n",
       "0  pioneer touch screen with reverse camera, 16\" ...               NaN  \n",
       "1  multi-function steering wheel, keyless entry, ...               NaN  \n",
       "2  18\" sports rims, sports leather seats, navigat...               NaN  \n",
       "3  push start button, toyota factory player, reve...               NaN  \n",
       "4  factory fitted audio with audio & multi functi...               NaN  \n",
       "\n",
       "[5 rows x 29 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>title</th>\n",
       "      <th>make</th>\n",
       "      <th>model</th>\n",
       "      <th>description</th>\n",
       "      <th>manufactured</th>\n",
       "      <th>original_reg_date</th>\n",
       "      <th>reg_date</th>\n",
       "      <th>type_of_vehicle</th>\n",
       "      <th>category</th>\n",
       "      <th>...</th>\n",
       "      <th>dereg_value</th>\n",
       "      <th>mileage</th>\n",
       "      <th>omv</th>\n",
       "      <th>arf</th>\n",
       "      <th>opc_scheme</th>\n",
       "      <th>lifespan</th>\n",
       "      <th>eco_category</th>\n",
       "      <th>features</th>\n",
       "      <th>accessories</th>\n",
       "      <th>indicative_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1303772</td>\n",
       "      <td>Honda Vezel 1.5A X</td>\n",
       "      <td>honda</td>\n",
       "      <td>vezel</td>\n",
       "      <td>4614</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29-apr-2015</td>\n",
       "      <td>suv</td>\n",
       "      <td>parf car</td>\n",
       "      <td>...</td>\n",
       "      <td>9582.0</td>\n",
       "      <td>112000.0</td>\n",
       "      <td>19229.0</td>\n",
       "      <td>9229.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uncategorized</td>\n",
       "      <td>powerful 1.5l i-vtec engine producing 128bhp, ...</td>\n",
       "      <td>pioneer touch screen with reverse camera, 16\" ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1323166</td>\n",
       "      <td>Mazda 3 1.6A SP (COE till 10/2027)</td>\n",
       "      <td>mazda</td>\n",
       "      <td>3</td>\n",
       "      <td>extremely well maintained and in pristine cond...</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26-oct-2007</td>\n",
       "      <td>mid-sized sedan</td>\n",
       "      <td>coe car, premium ad car, low mileage car</td>\n",
       "      <td>...</td>\n",
       "      <td>13644.0</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>14347.0</td>\n",
       "      <td>15782.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uncategorized</td>\n",
       "      <td>fuel efficient 1.6l 4-cylinder inline 16-valve...</td>\n",
       "      <td>multi-function steering wheel, keyless entry, ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1308405</td>\n",
       "      <td>MINI Cooper S Countryman 2.0A</td>\n",
       "      <td>mini</td>\n",
       "      <td>cooper</td>\n",
       "      <td>1 owner! beautiful island blue color! eurokars...</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27-mar-2020</td>\n",
       "      <td>sports car</td>\n",
       "      <td>parf car</td>\n",
       "      <td>...</td>\n",
       "      <td>54818.0</td>\n",
       "      <td>43000.0</td>\n",
       "      <td>39863.0</td>\n",
       "      <td>47809.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uncategorized</td>\n",
       "      <td>output of 141kw, 189bhp at 5000rpm to 6000rpm,...</td>\n",
       "      <td>18\" sports rims, sports leather seats, navigat...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1216706</td>\n",
       "      <td>Toyota Vios 1.5A G</td>\n",
       "      <td>toyota</td>\n",
       "      <td>vios</td>\n",
       "      <td>fully agent maintain! genuine low mileage at 5...</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28-jun-2019</td>\n",
       "      <td>mid-sized sedan</td>\n",
       "      <td>parf car, premium ad car</td>\n",
       "      <td>...</td>\n",
       "      <td>26363.0</td>\n",
       "      <td>53300.0</td>\n",
       "      <td>15573.0</td>\n",
       "      <td>15573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uncategorized</td>\n",
       "      <td>1.5l 4 cylinder 16 valves dohc vvt-i engine, 7...</td>\n",
       "      <td>push start button, toyota factory player, reve...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1298206</td>\n",
       "      <td>Mazda 3 HB 1.5A</td>\n",
       "      <td>mazda</td>\n",
       "      <td>3</td>\n",
       "      <td>workshop check/sta evaluation available. accid...</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19-nov-2015</td>\n",
       "      <td>hatchback</td>\n",
       "      <td>parf car, premium ad car</td>\n",
       "      <td>...</td>\n",
       "      <td>15197.0</td>\n",
       "      <td>149000.0</td>\n",
       "      <td>18097.0</td>\n",
       "      <td>13097.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uncategorized</td>\n",
       "      <td>1.5l 4 cylinder inline dohc 16 valves skyactiv...</td>\n",
       "      <td>factory fitted audio with audio &amp; multi functi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T23:05:58.590533Z",
     "start_time": "2024-10-08T23:05:54.479243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "preprocessor = DataPreprocessor()\n",
    "\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "\n",
    "train_df = train_df.dropna(subset=[target])\n",
    "\n",
    "preprocessor.fit(train_df)\n",
    "\n",
    "train_df = preprocessor.transform(train_df)\n",
    "test_df = preprocessor.transform(test_df)\n",
    "test_df = test_df[features]\n",
    "\n",
    "# Load the best model with the pipeline, which includes preprocessing steps\n",
    "best_model = joblib.load('best_xgb_model.pkl')\n",
    "\n",
    "# Ensure that the target column 'price' is not in the test dataset\n",
    "if 'price' in test_df.columns:\n",
    "    test_df = test_df.drop(columns=['price'])\n",
    "\n",
    "# Make predictions using the test dataset with the best model\n",
    "test_predictions = best_model.predict(test_df)\n",
    "\n",
    "# Create a DataFrame with the predictions\n",
    "output = pd.DataFrame({'Id': test_df.index, 'Predicted': test_predictions})\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "output.to_csv('predictions_v1.1.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the output DataFrame\n",
    "print(output.head())\n"
   ],
   "id": "d5b1613da314774",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id      Predicted\n",
      "0   0   20147.593750\n",
      "1   1   35544.964844\n",
      "2   2  146033.046875\n",
      "3   3   79854.781250\n",
      "4   4   26131.941406\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "82f1cd8d0f43d666"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
