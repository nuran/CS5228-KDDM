{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-08T22:52:40.463797Z",
     "start_time": "2024-10-08T22:52:40.334703Z"
    }
   },
   "id": "33768d0076b0f95d",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-08T22:52:42.799575Z",
     "start_time": "2024-10-08T22:52:40.472802Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "class DataPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.model_to_make_mapping = None\n",
    "        self.overall_medians = {}\n",
    "\n",
    "    def fit(self, train_df):\n",
    "        \"\"\"\n",
    "        Fit the preprocessing on the training data to create mappings and overall statistics.\n",
    "        \"\"\"\n",
    "        # Create model_to_make mapping using non-null entries in the training dataset\n",
    "        self.model_to_make_mapping = train_df.dropna(subset=['make']).set_index('model')['make'].str.lower().to_dict()\n",
    "\n",
    "        # Calculate overall medians for columns where necessary\n",
    "        self.overall_medians = {\n",
    "            'manufactured': train_df['manufactured'].median(),\n",
    "            'power': train_df['power'].median(),\n",
    "            'mileage': train_df['mileage'].median(),\n",
    "            'engine_cap': train_df['engine_cap'].median(),\n",
    "            'depreciation': train_df['depreciation'].median(),\n",
    "            'road_tax': train_df['road_tax'].mean(),\n",
    "            'dereg_value': train_df['dereg_value'].mean(),\n",
    "            'coe': train_df['coe'].mean(),\n",
    "            'omv': train_df['omv'].mean(),\n",
    "            'arf': train_df['arf'].mean(),\n",
    "        }\n",
    "\n",
    "    def fill_missing_make(self, df):\n",
    "        \"\"\"\n",
    "        Fill missing values in the 'make' column using the 'model' column based on the mapping dictionary.\n",
    "        \"\"\"\n",
    "        def derive_make_from_model(row):\n",
    "            if pd.isnull(row['make']):\n",
    "                return self.model_to_make_mapping.get(row['model'].lower(), None)\n",
    "            else:\n",
    "                return row['make']\n",
    "\n",
    "        df['make'] = df.apply(derive_make_from_model, axis=1)\n",
    "\n",
    "    def fill_missing_with_group_mode_or_median(self, df, column_name):\n",
    "        \"\"\"\n",
    "        Fill missing values in a specified column using the mode of each group (model).\n",
    "        If the mode is not available, use the median of the training dataset.\n",
    "        \"\"\"\n",
    "        overall_median = self.overall_medians[column_name]\n",
    "        df[column_name] = df.groupby('model')[column_name].transform(\n",
    "            lambda x: x.fillna(x.mode().iloc[0] if not x.mode().empty else overall_median)\n",
    "        )\n",
    "\n",
    "    def fill_missing_with_group_mean_or_median(self, df, column_name):\n",
    "        \"\"\"\n",
    "        Fill missing values in a specified column using the mean of each group (model).\n",
    "        If the group mean is not available, use the overall mean from the training dataset.\n",
    "        \"\"\"\n",
    "        overall_mean = self.overall_medians[column_name]\n",
    "        df[column_name] = df.groupby('model')[column_name].transform(\n",
    "            lambda x: x.fillna(x.mean() if not x.mode().empty else overall_mean)\n",
    "        )\n",
    "\n",
    "    def transform(self, df):\n",
    "        \"\"\"\n",
    "        Apply the preprocessing steps to a dataset (training or test) using the fitted parameters.\n",
    "        \"\"\"\n",
    "        # Fill missing 'make' values using model information\n",
    "        self.fill_missing_make(df)\n",
    "\n",
    "        # Fill missing values for other columns using appropriate methods\n",
    "        self.fill_missing_with_group_mode_or_median(df, 'manufactured')\n",
    "        self.fill_missing_with_group_mode_or_median(df, 'power')\n",
    "        self.fill_missing_with_group_mode_or_median(df, 'mileage')\n",
    "        self.fill_missing_with_group_mode_or_median(df, 'engine_cap')\n",
    "        self.fill_missing_with_group_mode_or_median(df, 'depreciation')\n",
    "        self.fill_missing_with_group_mode_or_median(df, 'road_tax')\n",
    "        self.fill_missing_with_group_mean_or_median(df, 'dereg_value')\n",
    "        self.fill_missing_with_group_mean_or_median(df, 'coe')\n",
    "        self.fill_missing_with_group_mean_or_median(df, 'omv')\n",
    "        self.fill_missing_with_group_mean_or_median(df, 'arf')\n",
    "\n",
    "        return df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-08T22:52:45.208419Z",
     "start_time": "2024-10-08T22:52:44.824508Z"
    }
   },
   "id": "907431efd08dbee",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T22:53:48.433934Z",
     "start_time": "2024-10-08T22:53:44.862442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "features = ['make', 'model','type_of_vehicle', 'manufactured', 'mileage', 'power','engine_cap', 'depreciation','road_tax','dereg_value','coe', 'omv', 'arf' ]\n",
    "target = 'price'\n",
    "numerical_features = ['manufactured', 'mileage', 'power','engine_cap', 'depreciation','road_tax','dereg_value','coe', 'omv', 'arf']\n",
    "categorical_features = ['make', 'model','type_of_vehicle']\n",
    "\n",
    "preprocessor = DataPreprocessor()\n",
    "\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "\n",
    "train_df = train_df.dropna(subset=[target])\n",
    "\n",
    "preprocessor.fit(train_df)\n",
    "\n",
    "train_df = preprocessor.transform(train_df)\n",
    "test_df = preprocessor.transform(test_df)\n",
    "\n",
    "X = train_df[features]\n",
    "y = train_df[target]\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "id": "4e965ec1ce855863",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# Step 3: Create preprocessing pipelines for both numeric and categorical features\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Step 4: Combine preprocessing steps into a column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Step 5: Create a pipeline that first preprocesses the data and then applies the XGBoost model\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    # ('model', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "    ('model', XGBRegressor(n_estimators=500, learning_rate=0.1, max_depth=20, random_state=42))\n",
    "])\n",
    "\n",
    "# Step 6: Split the data into training and testing sets\n",
    "\n",
    "\n",
    "# Step 7: Fit the model pipeline to the training data\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Step 8: Make predictions on the test set\n",
    "y_pred = model_pipeline.predict(X_valid)\n",
    "\n",
    "# Step 9: Evaluate the model's performance\n",
    "mae = mean_absolute_error(y_valid, y_pred)\n",
    "mse = mean_squared_error(y_valid, y_pred)\n",
    "rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
    "r2 = r2_score(y_valid, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f'Mean Absolute Error (MAE): {mae:.2f}')\n",
    "print(f'Mean Squared Error (MSE): {mse:.2f}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse:.2f}')\n",
    "print(f'R-squared (R2): {r2:.2f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-08T22:53:03.690254Z",
     "start_time": "2024-10-08T22:52:52.759890Z"
    }
   },
   "id": "c562da927fb83a5c",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 51\u001B[0m\n\u001B[0;32m     48\u001B[0m X_train, X_valid, y_train, y_valid \u001B[38;5;241m=\u001B[39m train_test_split(X, y, test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.2\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n\u001B[0;32m     50\u001B[0m \u001B[38;5;66;03m# Step 7: Fit the model pipeline to the training data\u001B[39;00m\n\u001B[1;32m---> 51\u001B[0m \u001B[43mmodel_pipeline\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     53\u001B[0m \u001B[38;5;66;03m# Step 8: Make predictions on the test set\u001B[39;00m\n\u001B[0;32m     54\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m model_pipeline\u001B[38;5;241m.\u001B[39mpredict(X_valid)\n",
      "File \u001B[1;32mH:\\bin\\envs\\sem4_assignments\\Lib\\site-packages\\sklearn\\base.py:1473\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1466\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1468\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1469\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1470\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1471\u001B[0m     )\n\u001B[0;32m   1472\u001B[0m ):\n\u001B[1;32m-> 1473\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mH:\\bin\\envs\\sem4_assignments\\Lib\\site-packages\\sklearn\\pipeline.py:473\u001B[0m, in \u001B[0;36mPipeline.fit\u001B[1;34m(self, X, y, **params)\u001B[0m\n\u001B[0;32m    471\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_final_estimator \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpassthrough\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    472\u001B[0m         last_step_params \u001B[38;5;241m=\u001B[39m routed_params[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msteps[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m][\u001B[38;5;241m0\u001B[39m]]\n\u001B[1;32m--> 473\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_final_estimator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mXt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mlast_step_params\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfit\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    475\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32mH:\\bin\\envs\\sem4_assignments\\Lib\\site-packages\\xgboost\\core.py:726\u001B[0m, in \u001B[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    724\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sig\u001B[38;5;241m.\u001B[39mparameters, args):\n\u001B[0;32m    725\u001B[0m     kwargs[k] \u001B[38;5;241m=\u001B[39m arg\n\u001B[1;32m--> 726\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mH:\\bin\\envs\\sem4_assignments\\Lib\\site-packages\\xgboost\\sklearn.py:1108\u001B[0m, in \u001B[0;36mXGBModel.fit\u001B[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001B[0m\n\u001B[0;32m   1105\u001B[0m     obj \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m model, metric, params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_configure_fit(xgb_model, params)\n\u001B[1;32m-> 1108\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_Booster \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1109\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1110\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_dmatrix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1111\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_num_boosting_rounds\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1112\u001B[0m \u001B[43m    \u001B[49m\u001B[43mevals\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mevals\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1113\u001B[0m \u001B[43m    \u001B[49m\u001B[43mearly_stopping_rounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mearly_stopping_rounds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1114\u001B[0m \u001B[43m    \u001B[49m\u001B[43mevals_result\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mevals_result\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1115\u001B[0m \u001B[43m    \u001B[49m\u001B[43mobj\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1116\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcustom_metric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetric\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1117\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1118\u001B[0m \u001B[43m    \u001B[49m\u001B[43mxgb_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1119\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1120\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1122\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_evaluation_result(evals_result)\n\u001B[0;32m   1123\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32mH:\\bin\\envs\\sem4_assignments\\Lib\\site-packages\\xgboost\\core.py:726\u001B[0m, in \u001B[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    724\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sig\u001B[38;5;241m.\u001B[39mparameters, args):\n\u001B[0;32m    725\u001B[0m     kwargs[k] \u001B[38;5;241m=\u001B[39m arg\n\u001B[1;32m--> 726\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mH:\\bin\\envs\\sem4_assignments\\Lib\\site-packages\\xgboost\\training.py:181\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001B[0m\n\u001B[0;32m    179\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cb_container\u001B[38;5;241m.\u001B[39mbefore_iteration(bst, i, dtrain, evals):\n\u001B[0;32m    180\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m--> 181\u001B[0m \u001B[43mbst\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43miteration\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfobj\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    182\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cb_container\u001B[38;5;241m.\u001B[39mafter_iteration(bst, i, dtrain, evals):\n\u001B[0;32m    183\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32mH:\\bin\\envs\\sem4_assignments\\Lib\\site-packages\\xgboost\\core.py:2101\u001B[0m, in \u001B[0;36mBooster.update\u001B[1;34m(self, dtrain, iteration, fobj)\u001B[0m\n\u001B[0;32m   2097\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_assign_dmatrix_features(dtrain)\n\u001B[0;32m   2099\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m fobj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   2100\u001B[0m     _check_call(\n\u001B[1;32m-> 2101\u001B[0m         \u001B[43m_LIB\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mXGBoosterUpdateOneIter\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2102\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mc_int\u001B[49m\u001B[43m(\u001B[49m\u001B[43miteration\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtrain\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle\u001B[49m\n\u001B[0;32m   2103\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2104\u001B[0m     )\n\u001B[0;32m   2105\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   2106\u001B[0m     pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredict(dtrain, output_margin\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T17:04:29.533332Z",
     "start_time": "2024-10-08T17:04:29.419160Z"
    }
   },
   "cell_type": "code",
   "source": "X_train.head()",
   "id": "b7da6d208d7e4a45",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         make   model  manufactured   mileage  power  engine_cap  \\\n",
       "23311   isuzu   npr85        2019.0   14329.0  111.0      2999.0   \n",
       "23623   honda     fit        2009.0   55000.0   73.0      1339.0   \n",
       "1020   toyota  sienta        2018.0   80346.0   79.0      1496.0   \n",
       "12645   volvo     v40        2018.0   68000.0  140.0      1969.0   \n",
       "1533      kia  carens        2015.0  130000.0  122.0      1999.0   \n",
       "\n",
       "       depreciation     road_tax  dereg_value    coe      omv      arf  \\\n",
       "23311       14860.0  1462.160899      13348.0  22085  37994.0   1900.0   \n",
       "23623       13510.0   885.000000        123.0  14920  14211.0  14211.0   \n",
       "1020        14530.0   682.000000      25880.0  38001  17199.0  17199.0   \n",
       "12645       15770.0  1176.000000      35358.0  36901  22799.0  23919.0   \n",
       "1533        15540.0  1212.000000      20117.0  58190  21074.0  21504.0   \n",
       "\n",
       "         price  \n",
       "23311  89800.0  \n",
       "23623    700.0  \n",
       "1020   64800.0  \n",
       "12645  92800.0  \n",
       "1533   32888.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>make</th>\n",
       "      <th>model</th>\n",
       "      <th>manufactured</th>\n",
       "      <th>mileage</th>\n",
       "      <th>power</th>\n",
       "      <th>engine_cap</th>\n",
       "      <th>depreciation</th>\n",
       "      <th>road_tax</th>\n",
       "      <th>dereg_value</th>\n",
       "      <th>coe</th>\n",
       "      <th>omv</th>\n",
       "      <th>arf</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23311</th>\n",
       "      <td>isuzu</td>\n",
       "      <td>npr85</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>14329.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>2999.0</td>\n",
       "      <td>14860.0</td>\n",
       "      <td>1462.160899</td>\n",
       "      <td>13348.0</td>\n",
       "      <td>22085</td>\n",
       "      <td>37994.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>89800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23623</th>\n",
       "      <td>honda</td>\n",
       "      <td>fit</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1339.0</td>\n",
       "      <td>13510.0</td>\n",
       "      <td>885.000000</td>\n",
       "      <td>123.0</td>\n",
       "      <td>14920</td>\n",
       "      <td>14211.0</td>\n",
       "      <td>14211.0</td>\n",
       "      <td>700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>toyota</td>\n",
       "      <td>sienta</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>80346.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1496.0</td>\n",
       "      <td>14530.0</td>\n",
       "      <td>682.000000</td>\n",
       "      <td>25880.0</td>\n",
       "      <td>38001</td>\n",
       "      <td>17199.0</td>\n",
       "      <td>17199.0</td>\n",
       "      <td>64800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12645</th>\n",
       "      <td>volvo</td>\n",
       "      <td>v40</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>68000.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>15770.0</td>\n",
       "      <td>1176.000000</td>\n",
       "      <td>35358.0</td>\n",
       "      <td>36901</td>\n",
       "      <td>22799.0</td>\n",
       "      <td>23919.0</td>\n",
       "      <td>92800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533</th>\n",
       "      <td>kia</td>\n",
       "      <td>carens</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>15540.0</td>\n",
       "      <td>1212.000000</td>\n",
       "      <td>20117.0</td>\n",
       "      <td>58190</td>\n",
       "      <td>21074.0</td>\n",
       "      <td>21504.0</td>\n",
       "      <td>32888.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Prepare a function to log model parameters and evaluation metrics. It should be in a single line saved to a csv for easy tracking.\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def log_model(model_name, model_params, evaluation_metrics):\n",
    "    \"\"\"\n",
    "    Log the model parameters and evaluation metrics to a CSV file.\n",
    "    \"\"\"\n",
    "    # Create a new CSV file if it does not exist\n",
    "    if not os.path.exists('model_logs.csv'):\n",
    "        with open('model_logs.csv', 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['Model', 'Parameters', 'MAE', 'MSE', 'RMSE', 'R2'])\n",
    "\n",
    "    # Append the results to the CSV file\n",
    "    with open('model_logs.csv', 'a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([model_name, model_params, *evaluation_metrics])"
   ],
   "id": "593818b18266a2b8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T23:05:43.578294Z",
     "start_time": "2024-10-08T22:53:51.904472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Assume you have X_train and X_valid as your training and validation datasets\n",
    "# Identify categorical and numerical features\n",
    "categorical_features = X_train.select_dtypes(include=['object']).columns\n",
    "numerical_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Preprocessing pipeline for categorical features (OneHotEncoder in this example)\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Preprocessing pipeline for numerical features\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean'))\n",
    "])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the complete pipeline including preprocessing and the XGBRegressor model\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', XGBRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'model__n_estimators': [100, 200, 500, 750, 1000],\n",
    "    'model__learning_rate': [0.01, 0.05, 0.075, 0.1, 0.2],\n",
    "    'model__max_depth': [3, 5, 10, 20, 30, 40, 50],\n",
    "    'model__subsample': [0.5, 0.6, 0.8, 1.0],\n",
    "    'model__colsample_bytree': [0.4, 0.6, 0.8, 1.0],\n",
    "    'model__min_child_weight': [1, 5, 10, 20]\n",
    "}\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=50,  # Number of different combinations to try\n",
    "    scoring='neg_mean_absolute_error',  # Use MAE as the scoring metric\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit the RandomizedSearchCV on the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model and parameters\n",
    "best_model = random_search.best_estimator_\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "# Save the best model to a file\n",
    "joblib.dump(best_model, 'best_xgb_model.pkl')\n",
    "\n",
    "# Evaluate the model with the best parameters on validation data\n",
    "y_pred = best_model.predict(X_valid)\n",
    "mae = mean_absolute_error(y_valid, y_pred)\n",
    "mse = mean_squared_error(y_valid, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f'Best Parameters: {best_params}')\n",
    "print(f'MAE: {mae}')\n",
    "print(f'MSE: {mse}')\n",
    "print(f'RMSE: {rmse}')\n",
    "\n",
    "\n"
   ],
   "id": "f17850a89c295da4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best Parameters: {'model__subsample': 0.8, 'model__n_estimators': 1000, 'model__min_child_weight': 5, 'model__max_depth': 40, 'model__learning_rate': 0.01, 'model__colsample_bytree': 1.0}\n",
      "MAE: 5311.081275683594\n",
      "MSE: 721255507.9106631\n",
      "RMSE: 26856.20054867522\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "test_predictions = model_pipeline.predict(test_df)\n",
    "output = pd.DataFrame({'Id': test_df.index, 'Predicted': test_predictions})\n",
    "output.to_csv('predictions_v1.1.csv', index=False)\n",
    "\n",
    "print(output.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-08T17:09:51.319681Z",
     "start_time": "2024-10-08T17:09:51.068883Z"
    }
   },
   "id": "77a6d42c08eac7af",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id      Predicted\n",
      "0   0   19547.953125\n",
      "1   1   35736.707031\n",
      "2   2  148128.781250\n",
      "3   3   78754.007812\n",
      "4   4   26880.107422\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "source": "test_df.head()",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-08T17:12:08.648631Z",
     "start_time": "2024-10-08T17:12:08.543791Z"
    }
   },
   "id": "cc20bcd85d2b911",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   listing_id                               title    make   model  \\\n",
       "0     1303772                  Honda Vezel 1.5A X   honda   vezel   \n",
       "1     1323166  Mazda 3 1.6A SP (COE till 10/2027)   mazda       3   \n",
       "2     1308405       MINI Cooper S Countryman 2.0A    mini  cooper   \n",
       "3     1216706                  Toyota Vios 1.5A G  toyota    vios   \n",
       "4     1298206                     Mazda 3 HB 1.5A   mazda       3   \n",
       "\n",
       "                                         description  manufactured  \\\n",
       "0                                               4614        2015.0   \n",
       "1  extremely well maintained and in pristine cond...        2007.0   \n",
       "2  1 owner! beautiful island blue color! eurokars...        2019.0   \n",
       "3  fully agent maintain! genuine low mileage at 5...        2019.0   \n",
       "4  workshop check/sta evaluation available. accid...        2015.0   \n",
       "\n",
       "  original_reg_date     reg_date  type_of_vehicle  \\\n",
       "0               NaN  29-apr-2015              suv   \n",
       "1               NaN  26-oct-2007  mid-sized sedan   \n",
       "2               NaN  27-mar-2020       sports car   \n",
       "3               NaN  28-jun-2019  mid-sized sedan   \n",
       "4               NaN  19-nov-2015        hatchback   \n",
       "\n",
       "                                   category  ... dereg_value   mileage  \\\n",
       "0                                  parf car  ...      9582.0  112000.0   \n",
       "1  coe car, premium ad car, low mileage car  ...     13644.0  120000.0   \n",
       "2                                  parf car  ...     54818.0   43000.0   \n",
       "3                  parf car, premium ad car  ...     26363.0   53300.0   \n",
       "4                  parf car, premium ad car  ...     15197.0  149000.0   \n",
       "\n",
       "       omv      arf  opc_scheme  lifespan   eco_category  \\\n",
       "0  19229.0   9229.0         NaN       NaN  uncategorized   \n",
       "1  14347.0  15782.0         NaN       NaN  uncategorized   \n",
       "2  39863.0  47809.0         NaN       NaN  uncategorized   \n",
       "3  15573.0  15573.0         NaN       NaN  uncategorized   \n",
       "4  18097.0  13097.0         NaN       NaN  uncategorized   \n",
       "\n",
       "                                            features  \\\n",
       "0  powerful 1.5l i-vtec engine producing 128bhp, ...   \n",
       "1  fuel efficient 1.6l 4-cylinder inline 16-valve...   \n",
       "2  output of 141kw, 189bhp at 5000rpm to 6000rpm,...   \n",
       "3  1.5l 4 cylinder 16 valves dohc vvt-i engine, 7...   \n",
       "4  1.5l 4 cylinder inline dohc 16 valves skyactiv...   \n",
       "\n",
       "                                         accessories  indicative_price  \n",
       "0  pioneer touch screen with reverse camera, 16\" ...               NaN  \n",
       "1  multi-function steering wheel, keyless entry, ...               NaN  \n",
       "2  18\" sports rims, sports leather seats, navigat...               NaN  \n",
       "3  push start button, toyota factory player, reve...               NaN  \n",
       "4  factory fitted audio with audio & multi functi...               NaN  \n",
       "\n",
       "[5 rows x 29 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>title</th>\n",
       "      <th>make</th>\n",
       "      <th>model</th>\n",
       "      <th>description</th>\n",
       "      <th>manufactured</th>\n",
       "      <th>original_reg_date</th>\n",
       "      <th>reg_date</th>\n",
       "      <th>type_of_vehicle</th>\n",
       "      <th>category</th>\n",
       "      <th>...</th>\n",
       "      <th>dereg_value</th>\n",
       "      <th>mileage</th>\n",
       "      <th>omv</th>\n",
       "      <th>arf</th>\n",
       "      <th>opc_scheme</th>\n",
       "      <th>lifespan</th>\n",
       "      <th>eco_category</th>\n",
       "      <th>features</th>\n",
       "      <th>accessories</th>\n",
       "      <th>indicative_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1303772</td>\n",
       "      <td>Honda Vezel 1.5A X</td>\n",
       "      <td>honda</td>\n",
       "      <td>vezel</td>\n",
       "      <td>4614</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29-apr-2015</td>\n",
       "      <td>suv</td>\n",
       "      <td>parf car</td>\n",
       "      <td>...</td>\n",
       "      <td>9582.0</td>\n",
       "      <td>112000.0</td>\n",
       "      <td>19229.0</td>\n",
       "      <td>9229.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uncategorized</td>\n",
       "      <td>powerful 1.5l i-vtec engine producing 128bhp, ...</td>\n",
       "      <td>pioneer touch screen with reverse camera, 16\" ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1323166</td>\n",
       "      <td>Mazda 3 1.6A SP (COE till 10/2027)</td>\n",
       "      <td>mazda</td>\n",
       "      <td>3</td>\n",
       "      <td>extremely well maintained and in pristine cond...</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26-oct-2007</td>\n",
       "      <td>mid-sized sedan</td>\n",
       "      <td>coe car, premium ad car, low mileage car</td>\n",
       "      <td>...</td>\n",
       "      <td>13644.0</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>14347.0</td>\n",
       "      <td>15782.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uncategorized</td>\n",
       "      <td>fuel efficient 1.6l 4-cylinder inline 16-valve...</td>\n",
       "      <td>multi-function steering wheel, keyless entry, ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1308405</td>\n",
       "      <td>MINI Cooper S Countryman 2.0A</td>\n",
       "      <td>mini</td>\n",
       "      <td>cooper</td>\n",
       "      <td>1 owner! beautiful island blue color! eurokars...</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27-mar-2020</td>\n",
       "      <td>sports car</td>\n",
       "      <td>parf car</td>\n",
       "      <td>...</td>\n",
       "      <td>54818.0</td>\n",
       "      <td>43000.0</td>\n",
       "      <td>39863.0</td>\n",
       "      <td>47809.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uncategorized</td>\n",
       "      <td>output of 141kw, 189bhp at 5000rpm to 6000rpm,...</td>\n",
       "      <td>18\" sports rims, sports leather seats, navigat...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1216706</td>\n",
       "      <td>Toyota Vios 1.5A G</td>\n",
       "      <td>toyota</td>\n",
       "      <td>vios</td>\n",
       "      <td>fully agent maintain! genuine low mileage at 5...</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28-jun-2019</td>\n",
       "      <td>mid-sized sedan</td>\n",
       "      <td>parf car, premium ad car</td>\n",
       "      <td>...</td>\n",
       "      <td>26363.0</td>\n",
       "      <td>53300.0</td>\n",
       "      <td>15573.0</td>\n",
       "      <td>15573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uncategorized</td>\n",
       "      <td>1.5l 4 cylinder 16 valves dohc vvt-i engine, 7...</td>\n",
       "      <td>push start button, toyota factory player, reve...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1298206</td>\n",
       "      <td>Mazda 3 HB 1.5A</td>\n",
       "      <td>mazda</td>\n",
       "      <td>3</td>\n",
       "      <td>workshop check/sta evaluation available. accid...</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19-nov-2015</td>\n",
       "      <td>hatchback</td>\n",
       "      <td>parf car, premium ad car</td>\n",
       "      <td>...</td>\n",
       "      <td>15197.0</td>\n",
       "      <td>149000.0</td>\n",
       "      <td>18097.0</td>\n",
       "      <td>13097.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uncategorized</td>\n",
       "      <td>1.5l 4 cylinder inline dohc 16 valves skyactiv...</td>\n",
       "      <td>factory fitted audio with audio &amp; multi functi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T23:05:58.590533Z",
     "start_time": "2024-10-08T23:05:54.479243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "preprocessor = DataPreprocessor()\n",
    "\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "\n",
    "train_df = train_df.dropna(subset=[target])\n",
    "\n",
    "preprocessor.fit(train_df)\n",
    "\n",
    "train_df = preprocessor.transform(train_df)\n",
    "test_df = preprocessor.transform(test_df)\n",
    "test_df = test_df[features]\n",
    "\n",
    "# Load the best model with the pipeline, which includes preprocessing steps\n",
    "best_model = joblib.load('best_xgb_model.pkl')\n",
    "\n",
    "# Ensure that the target column 'price' is not in the test dataset\n",
    "if 'price' in test_df.columns:\n",
    "    test_df = test_df.drop(columns=['price'])\n",
    "\n",
    "# Make predictions using the test dataset with the best model\n",
    "test_predictions = best_model.predict(test_df)\n",
    "\n",
    "# Create a DataFrame with the predictions\n",
    "output = pd.DataFrame({'Id': test_df.index, 'Predicted': test_predictions})\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "output.to_csv('predictions_v1.1.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the output DataFrame\n",
    "print(output.head())\n"
   ],
   "id": "d5b1613da314774",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id      Predicted\n",
      "0   0   20147.593750\n",
      "1   1   35544.964844\n",
      "2   2  146033.046875\n",
      "3   3   79854.781250\n",
      "4   4   26131.941406\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "82f1cd8d0f43d666"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
